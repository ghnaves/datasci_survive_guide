---
title: "Guia de Sobrevivência"
author: "Gustavo Givisiez"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    theme: journal
    highlight: tango
    code_folding: show
    self_contained: true
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introdução

## Minha história com sistemas operacionais

Sou formado no Windows desde seus primórdios. Meu primeiro computador (um 486 DX2 com 16 MB de RAM e 350 MB de HD) veio com o Windows 3.1 instalado. Mas minha principal demanda naquela época era o AutoCAD 12, que rodava no DOS e exigia a instalação de drivers de vídeo. Meus estudos iniciais eram para aprender MS-DOS, até que chegou o AutoCAD 13, que funcionava no Windows 3.1 e outras versões mais recentes nos. seus sucessores (95 e XP). Mas, nesses Windows recém-nascidos a arquitetura era toda baseada no MS-DOS, o que significava que o sistema operacional dependente de um sistema monotarefa.

Um dos grandes problemas dessas versões estava na instalação de softwares de terceiros. Havia a promessa de que o Painel de Controle > Adicionar/Remover Programas cuidaria de instalar e desinstalar. Mas existiam muitos problemas: o programa instalador do sistema apenas teoricamente gerenciava as instalações e, na prática, cada instalador .exe ou .msi fazia o que queria — copiava arquivos em múltiplas pastas (C:\Windows\System, C:\Program Files, C:\Documents and Settings etc.). Muitas dependências iam para a famosa DLL Hell que continham várias versões da mesma biblioteca misturadas. Por esses problemas, a instalação de aplicativos era um verdadeiro pesadelo e, ao desinstalar, quase sempre sobravam rastros: entradas no Registro do Windows, DLLs largadas, pastas esquecidas. Ou seja, tudo parecia ser centralizado, mas era um caos de fato. Na prática, muitos aplicativos deixavam rastros no sistema, como DLLs e outros arquivos que não eram removidos corretamente. Isso exigia reformatar o computador mais de uma vez ao ano para manter o sistema limpo e funcionando bem. Outros problemas me incomodavam: a estrutura de arquivos FAT16/FAT32 (limitada, sem journaling), um sistema de Registro instável e vulnerável à “DLL Hell” e uma base pouco adequada a multitarefa séria, pois o DOS (seu núcleo) entregava toda a memória para os aplicativos em execução.

O Windows NT, lançado em 1993, tinha uma arquitetura diferente e não dependente mais do DOS. Tinha sido criado para para ser robusto, multitarefa, para mais de multiprocessador e prometia segurança. Essa versão introduziu o NTFS (com journaling, permissões ACL, criptografia) nos computadores pessoais, que era baseado no Windows Server. Paralelamente conviviam “linhas” NT (Windows NT 3.1, 4.0, 2000) e consumer (95/98/ME). Ou seja, era um sistema misto NT + DOS. Foi no Windows XP (2001) que acorreu a fusão das linhas e que trouxe a base NT para o usuário comum trazendo mais estabilidade e segurança do que no 95/98. O NTFS se tornou padrão (com suporte para FAT32). Por outro lado, as DLL Hells permaneciam no sistema e os instaladores ainda tinha algum poder sobre ele. Embora não fosse mais tão caótico quanto antes as reinstalações do sistema eram frequentemente necessárias, especialmente após a instalação de muitos aplicativos. Minha história com o Windows se encerrou no Windows Vista, 7 e 8 (2007–2009), exatamente quando o modelo NTFS + arquitetura NT se consolidou e, aparentemente, nota-se a melhoria no User Account Control (UAC), com mais segurança e menos apps mexendo em pastas do sistema. Não tenho muita experiência nos versões posteriores (10 e 11) mas sei que há um reforço na sandbox de apps (ex: apps UWP/Store) e que hoje há um gerenciador de pacotes mais moderno: o winget (a partir de 2020) que é uma espécie de “Homebrew para Windows” ou o “apt-get do Ubuntu”. Sei que hoje a instalação é mais previsível, com rastreio e remoção mais limpa (pelo menos para apps da Store e winget) muito embora muitos .exe de terceiros ainda funcionam no “modelo antigo” e podem deixar rastros.

Foi por volta de 2013 (Windows 7 e 8) que eu migrei para o Mac. Observei que, diferente do Window, o Mac era baseado em plataforma Unix com controle muito superior sobre a memória e núcleo de processamento. A instalação de aplicativos já era feita principalmente por meio da Apple Store com alguns softwares baixados diretamente de empresas terceiras. A Apple é muito rigorosa com a certificação de softwares de terceiro e aplicativao não “aprovados” ou não funiconam ou funcionam sob muitos alertas de segurança. Formado no Windows, estava acostumado a baixar os instaladores e me pareceia natural. Mas, tenho de admitir que achava estranho a ideia de arratar um programa diretamente para a pasta de aplicativos. Copiar arquios .app para o /Appications era estranho como a sequencia de comandos do antigo MS-DOS, pois não dependia de um Painel de Controle > Adicionar/Remover Programas, que se era uma prática, há muito extinta no Windows, em que o arquivo .exe era copiado de umm disquete para um diretório e executado.


```{plaintext}
A:
A:\> dir
JOGO.EXE     123456  01-01-1993  12:00
README.TXT     1234  01-01-1993  12:00
A:\> copy JOGO.EXE C:\GAMES
        1 file(s) copied.
A:\> copy README.TXT C:\GAMES
        1 file(s) copied.
A:\> C:
C:\> cd GAMES
C:\GAMES> dir
JOGO.EXE
README.TXT
C:\GAMES> JOGO.EXE
```

Essa ideia de opiar o .app (um tipo de .exe) para o compurtador parecia um retrocesso pois ficava uma pergunta no ar: quem controlava o lixo dos instaladores? A resposta era simoples: o próprio MacOS controlada. Há no MacOS tem um sistema de instalação mais tradicional com instaladores .pkg (semelhante ao .msi do Windows) e que cuida de copiar arquivos para múltiplas pastas, mas a maioria dos aplicativos funcionava com o simples arrastar e soltar. A instalação era feita em um único diretório (/Applications) e a desinstalação era tão simples quanto arrastar o aplicativo para a lixeira. Fui percebendo que as certificaçoes e padronizações da Apple quase eliminavam os problemas que eu enfrentava no Windows, como rastros deixados no sistema.

No entanto, sempre fui muito curioso e estou sempre instaladndo aplicativos, banco de dados, gerenciadores de máquinas virtuais, compiladores e toda a fauna que todo nerd de computador que se preze tem de testar. A medida que o tempo foi passando que eu fui percebendo, para a minha surpresa, que o MscOS também deixava os programas instalarem lixo ou eu mesmo, na maioria da vezes, não sabia muito bem o que fazia. Foi quandom, estudando Data Science, percebi que havia algo que esses profissionais chamavam de gerenciador de pacotes e fui apresentado ao Homebrew que é um gerenciador de pacotes muito eficiente.

Aqui vale um parênteses. O Windows e macOS, desde o início, tiveram como prioridade a experiência do usuário: menus, janelas, botões. O usuário não precisava (nem devia) ver o que acontecia “por baixo”. O Windows se popularizou a ideia de “point and click”, escondendo a complexidade e o macOS (e antes, o Mac OS clássico) sempre foi referência de design e usabilidade, pensando no público não-técnico. Penso que a Apple ainda levada essa indissociabilidade entre a interface e o sistema a um nível quase obsessivo. Se para mim a linha de comandos DOS foi progressivamente se escondendo dos olhos do usuário, o terminal do macOS demorou anos para virar meu amigo e para demosntrar sua função (exceto para automatizações). O Linux, por outro lado, nasceu com outro objetivo: estabilidade, controle e flexibilidade. O foco inicial eram programadores e administradores de sistemas, não usuários comuns. As interfaces gráficas existiam (KDE, Gnome, etc.) mas sempre foram camadas opcionais que muitas vezes eram pesadas, instáveis ou mal integradas. O que realmente funcionava (e ainda funciona) era o terminal e para mim, com as interfaces gráficas sempre sussurrando e imponta sua pretensa superioridade, o Linux me parecia um grande retrocesso.

Perceber que o retorno ao terminal era uma evolução e um amadurecimento foi uma quebra de paradigma. O terminal não era um retrocesso, mas uma ferramenta poderosa que me permitia controlar o sistema de forma mais eficiente. O Homebrew, com sua simplicidade e eficiência controla melhor a instalação e gerenciamento de softwares no macOS. Ele traz a promessa de um sistema mais limpo, organizado e fácil de manter.

No entanto, nunca deixei de observar o Linux. Mas, durante muito tempo, ele me pareceu mais um manifesto político do que um sistema operacional para o dia a dia: uma ferramenta *contra* big techs, para entusiastas de software livre e defensores da independência digital. De certa forma, essa impressão não é totalmente incorreta. O Linux nasceu como alternativa comunitária, e até hoje carrega um caráter de resistência. Funciona impressionantemente bem em hardwares antigos, ressuscitando máquinas consideradas obsoletas pelo Windows ou pelo macOS. É incrivelmente flexível: tudo pode ser configurado, recompilado e ajustado. Essa liberdade, porém, vem acompanhada de uma complexidade que assusta o usuário comum.

E há outro ponto: para quem depende de certos softwares comerciais (Adobe, Microsoft Office, AutoCAD, etc.), o Linux ainda é bem limitado. Existem alternativas como LibreOffice, GIMP e Inkscape, que atendem a muitas demandas, mas raramente substituem integralmente suas contrapartes proprietárias. Até os jogos, que por muito tempo foram uma barreira, hoje rodam de forma surpreendente via Steam Proton — mas ainda ficam atrás do ecossistema do Windows.

Onde o Linux realmente brilha é em três frentes: servidores, supercomputação e desenvolvimento. Ele é a espinha dorsal da internet moderna, dominando datacenters e serviços em nuvem. É também o ambiente preferencial para programadores, cientistas de dados e engenheiros de software, justamente por ser estável, seguro, leve e altamente personalizável. Nesse campo, o Linux não é *alternativa*, mas o **padrão**.

Essa diferença de propósitos fica clara quando comparo as filosofias. Windows e macOS sempre priorizaram a experiência do usuário: esconderam a complexidade, apostaram em interfaces gráficas coesas, minimizaram a exposição ao terminal. O Linux fez o caminho oposto: nasceu para administradores e desenvolvedores, e as interfaces gráficas sempre foram opcionais, um verniz colocado sobre o núcleo. Perceber que o *retorno ao terminal* não foi um retrocesso, mas sim evolução, foi uma quebra de paradigma pessoal. Hoje, vejo o terminal como ferramenta madura, que oferece controle e previsibilidade, ao invés de confusão.

Lembro-me também do OS/2 Warp, da IBM. Ele surgiu com propostas parecidas às do Linux: estabilidade, multitarefa real, suporte avançado quando o Windows ainda era frágil. Mas perdeu a guerra comercial para o Windows 95, que era mais amigável e vinha com marketing pesado. O OS/2 resistiu em nichos bancários e corporativos, mas acabou esquecido, sobrevivendo apenas em projetos de nicho como o ArcaOS. Um bom lembrete de que qualidade técnica nem sempre basta sem adesão de mercado.

Assim, minha trajetória entre sistemas operacionais é, em parte, também uma história de filosofias distintas. O Windows me ensinou informática no caos de DLLs e reinstalações constantes. O macOS me trouxe estabilidade e refinamento de usabilidade, com Homebrew como ferramenta indispensável. O Linux, por sua vez, me apresenta liberdade absoluta e poder técnico, mas cobra atenção, aprendizado e — muitas vezes — algum sacrifício em softwares comerciais. Não há um “sistema perfeito”, mas cada um traz a marca de seu tempo, da sua comunidade e da sua filosofia de design.


